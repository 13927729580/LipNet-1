{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential # To initialise the nn as a sequence of layers\n",
    "from keras.layers import Convolution2D # To make the convolution layer for 2D images\n",
    "from keras.layers import MaxPooling2D # \n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "csv=CSVLogger(\"First_model.log\")\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32,(2,2),input_shape = (224,224,1), activation = 'relu',strides=2,name='convo1'))\n",
    "classifier.add(Convolution2D(64,(3,3), activation = 'relu',name='convo2'))\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(64,(3,3),activation = 'relu',name='convo3'))\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Convolution2D(64,(3,3),activation = 'relu',name='convo4'))\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout((0.5)))\n",
    "classifier.add(Dense(1024, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout((0.4)))\n",
    "classifier.add(Dense(20, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2600 images belonging to 20 classes.\n",
      "Found 200 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('Train',target_size=(224, 224),batch_size=32,class_mode='categorical',color_mode='grayscale')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dev',target_size=(224, 224),batch_size=32,class_mode='categorical',color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 00000: val_acc improved from -inf to 0.50960, saving model to weights-improvement-00-0.51.hdf5\n",
      "314s - loss: 0.3649 - acc: 0.8924 - val_loss: 3.8966 - val_acc: 0.5096\n",
      "Epoch 2/10\n",
      "Epoch 00001: val_acc did not improve\n",
      "307s - loss: 0.0349 - acc: 0.9886 - val_loss: 5.1977 - val_acc: 0.4852\n",
      "Epoch 3/10\n",
      "Epoch 00002: val_acc did not improve\n",
      "307s - loss: 0.0204 - acc: 0.9931 - val_loss: 4.5596 - val_acc: 0.4495\n",
      "Epoch 4/10\n",
      "Epoch 00003: val_acc did not improve\n",
      "307s - loss: 0.0181 - acc: 0.9943 - val_loss: 6.1149 - val_acc: 0.3698\n",
      "Epoch 5/10\n",
      "Epoch 00004: val_acc did not improve\n",
      "306s - loss: 0.0157 - acc: 0.9948 - val_loss: 4.9185 - val_acc: 0.4907\n",
      "Epoch 6/10\n",
      "Epoch 00005: val_acc improved from 0.50960 to 0.51030, saving model to weights-improvement-05-0.51.hdf5\n",
      "308s - loss: 0.0161 - acc: 0.9949 - val_loss: 3.5253 - val_acc: 0.5103\n",
      "Epoch 7/10\n",
      "Epoch 00006: val_acc did not improve\n",
      "309s - loss: 0.0187 - acc: 0.9942 - val_loss: 4.4108 - val_acc: 0.4648\n",
      "Epoch 8/10\n",
      "Epoch 00007: val_acc did not improve\n",
      "308s - loss: 0.0186 - acc: 0.9942 - val_loss: 3.9813 - val_acc: 0.5044\n",
      "Epoch 9/10\n",
      "Epoch 00008: val_acc did not improve\n",
      "308s - loss: 0.0207 - acc: 0.9934 - val_loss: 4.4472 - val_acc: 0.4754\n",
      "Epoch 10/10\n",
      "Epoch 00009: val_acc did not improve\n",
      "308s - loss: 0.0163 - acc: 0.9949 - val_loss: 4.8096 - val_acc: 0.4593\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit_generator(train_set,steps_per_epoch=2600,epochs=10,validation_data=test_set,validation_steps=200,callbacks=[csv,checkpoint],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.save('First_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
